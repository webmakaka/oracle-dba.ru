---
layout: page
title: Утилиты экспорта и импорта данных Data Pump
permalink: /docs/oracle-database/backup-and-restore/oracle-data-pump/
---

## Утилиты экспорта и импорта данных Data Pump

В состав технологии Data Pump входят утилиты: Data Pump Export (expdp) и Data Pump Import (impdp).

Data Pump Export – выгружает данные в файлы операционной системы, называемые файлами дампа (dumps files), в специальном формате, который может понимать только утилита Data Pump Import.


Получить справку по утилитам можно выполнив команды:


    expdp help=y
    impdp help=y



Если необходимо выполнить экспорт схемы или ее объектов, воспользуйтесь правами данной схемы. Использовать полномочия учетных записей sys и system не рекомендуется (по той причине, что для импорта могут потребоваться права sys и  system соотвестственно).


Файл параметров экспорта схемы.



    vi exoprt_schema_name.config

<br/>

    JOB_NAME=impdp_schema_name
    DUMPFILE=dpdumps:schema_name.dmp
    LOGFILE=dplogs:expdp_schema_name_YYYYMMDD.log


JOB_NAME - имя задания, чтобы при необходимости задание можно было бы идентифицировать по имени.

DUMPFILE - каталог для дампа
LOGFILE - каталог для логов


dplogs - ссылка в базе данных на каталог в котором должны будут сохраниться логи результата выполнения экспорта схемы базы данных.

dpdumps - ссылка в базе данных на каталог в котором должны будут сохраниться файл дампа базы данных.



dplogs и dpdumps должны ссылаться на реальные каталоги операционной системы с достаточным набором прав на запись.


    # mkdir -p /u03/oradata/datapump/dumps
    # mkdir -p /u03/oradata/datapump/logs

<br/>

    # chown -R oracle11:dba /u03/oradata/datapump/dumps
    # chown -R oracle11:dba /u03/oradata/datapump/logs



Создание ссылки в базе данных на катлоги операционной системы



    $ sqlplus / as sysdba



<strong>Посмотреть уже имеющиеся каталоги для datapump:</strong>

    SQL> set linesize 200;
    SQL> set pagesize 0;
    SQL> col directory_name format a30;
    SQL> col directory_path format a60;
    SQL> select directory_name, directory_path from dba_directories;



Мне не нравится каталог по умолчанию. Предпочитаю его удалить

    DROP DIRECTORY DATA_PUMP_DIR;


Создаю директории

    CREATE DIRECTORY  dpdumps  as '/u03/oradata/datapump/dumps';
    CREATE DIRECTORY  dplogs   as '/u03/oradata/datapump/logs';


Делегирую права на запись в данную директорию пользователю scott

    GRANT READ, WRITE ON DIRECTORY dpdumps TO scott;
    GRANT READ, WRITE ON DIRECTORY dplogs TO scott;


Если необходимо предоставить возможность экспорта данных в указанные каталоги для любых схем:

    GRANT READ, WRITE ON DIRECTORY dpdumps TO PUBLIC;
    GRANT READ, WRITE ON DIRECTORY dplogs TO PUBLIC;


<strong>Экспорт схемы с использованием файла параметров:</strong>


    $ nohup expdp scott/tiger parfile=exoprt_schema_name.config &


В некоторых случаях необходимо явно указать SID базы данных.

$ nohup expdp scott/tiger@SID parfile=exoprt_schema_name.config &



<strong>Экспорт можно выполнить одной командой без использования файла параметров:</strong>


    $ nohup expdp scott/tiger job_name=scott_export_job_01 dumpfile=dpdumps:scott_YYYYMMDD.dmp logfile=dplogs:scott_YYYYMMDD  &

<br/><br/>


<strong>Технология Data Pump состоит из трех главных компонентов:</strong>


<ul>
	<li>Пакет DBMS_DATAPUMP – это главный механизм для осуществления загрузки и выгрузки метаданных словаря данных. В пакете DBMS_DATAPUMP  содержится основополагающие элементы технологии Data Pump в виде процедур, которые в действиельности приводят в действие задания по загрузке и выгрузке данных. Содержимое этого пакета отвечает за работу как утилиты Data Pump export, так и утилиты Data Pump Import.</li>
	<li>Пакет DBMS_METADATA – для извлечения и изменения метаданных Oracle.</li>
	<li>Клиенты с интерфейсом командной строки – impdbp и expdp</li>
</ul>


<br/>
<h3>Режимы утилиты Data Pump Export</h3>


<strong>Data Pump Export поддерживает несколько режимов для выполнения заданий.</strong>


<ul>
	<li>Режим экспорта всей базы данных. Позволяет выполнять экспорт всей базы данных за один сеанс экспорта с помощью параметра FULL. Для использования этого режима, необходимы привилегии EXPORT_FULL_DATABASE.</li>
	<li>Режим схем. Позволяет выполнять экспорт данных и/или объектов только конкретного пользователя с помощью параметра SCHEMAS.</li>
	<li>Режим табличных пространств. Позволяет выполнять экспорт всех таблиц, которые содержатся в одном или нескольких табливчных пространствах, с помощью параметра TABLESPACES или только метаданных тех объектов, которые содержатся в одном или нескольких табличных пространствах, с помощью параметра TRANSPORT_TABLESPACES. Выполнять экспорт табличных пространств между базами данных можно, чначала выполнив экспорт метаданных, затем скопировав файлы табличного пространства на целевой сервер, а потом импортировав метаданные в целевую базу данных.</li>
	<li>Режим таблиц. Позволяет выполнять экспорт только одной или нескольких конкретных таблиц с помощью параметра TABLES. </li>
</ul>


По умолчанию для выполнения заданий Data Pump Export и Data Pump Import используется режим схем.



<strong>Параметры фильтрации экспортируемых данных.</strong>


Параметр CONTENT  - позволяет выполнять фильтрацию тех данных, которые должны помещаться в файл дампа при экспорте. Он может принимать следующие значения:


<ul>
	<li>ALL – указывает, что требуется экспортировать как данные таблиц, так и определения этих таблиц и других объектов (метаданных);</li>
	<li>DATA_ONLY – указывает, что требуется экспортировать только строки таблиц.</li>
	<li>METADATA_ONLY – указывает, что требуется экспортировать только метаданные.</li>
</ul>


Пример:

    nohup expdp scott/tiger dumpfile=dpdumps:mydump01.dmp logfile=dplogs:mydump01.log CONTENT=DATA_ONLY &



<strong>Парамтеры ECLUDE и INCLUDE</strong>


Параметры EXCLUDE и INCLUDE – это два взаимоисключающих параметра, которые можно применять для выполнения так называемой фильтрации метаданных (metadata filtering). Фильтрация метаданных позволяет выборочно исплючать или наоборот включать определенные типы объектов во время выполнения задания Data Pump Export или Data Pump Import. В преджней утилите экспорта для указания того, требуется ли экспортировать такие объекты, применялись параметры CONSTRAINTS, GRANTS и INDEXES. За счет использования параметров EXCLUDE и INCLUDE теперь стало можно включать и исключать объекты и многих других видов помимо тех четырех, фильтарцию которых можно было осуществлять ранее. Например, если необходимо сделать так, тобы во время экспорта не экспортировались никакие пакеты, такое поведение задается с помощью параметра EXCLUDE.




Проще говоря, параметр EXCLUDE помогает пропускать определенные типы объектво базы данных во время операции экспорта или импорта, а параметр INCLUDE наоборот – включать в эти операции только определенный набор объектов. Ниже показано, как в общем случае выглядит синтаксис этих параметров:



    EXCLUDE=тип_объекта[:конструкция_имени]
    INCLUDE=тип_объекта[:конструкция_имени]


Параметры EXCLUDE и INCLUDE являются взаимоисключащими. Поэтому во время выполенния одного и того же задания применять можно толкьо какой-то один из них; использовать тот и другой одновременно нельзя.


Как для параметра EXCLUDE, так и для параметра INCLUDE, элемент конструкция_имени является необязательным. Как известно, некоторые объекты в базе данных, например, таблицы, индексы, пакеты и процедуры, обладают именами, а некоторые, напримре, объекты GRANTS – нет. Элемент конструкция_имени в параметре EXCLUDE или INCLUDE позволяет приенять SQL-функцию для фильтрации именованных объектов.


Ниже приведен простой пример исключения всех таблиц, имя которые начинается с ECMP.


    EXCLUDE=TABLE:”LIKE ‘EMP%’”


В этом примере ”LIKE ‘EMP%’” пре конструкцию имени.


Элемент конструкция_имени является необязательным в параметрах EXCLUDE и INCLUDE. Он представляет собой просто средство фильтрации, позволяющее более точно определять тип подлежащих исключению или включению объектво (индексов, таблиц и т.д.). В случае его пропуска включаться или исключаться будут все объекты указанного типа.


В следующем примере Oracle исключит из операции экспорта все индексы, потому в элементе конструкция_имени не было указано никакого значения, требующего, чтобы исключались только определенные индексы:


    EXCLUDE=INDEX


Вдобавок параметр EXCLUDE может применяться для исключения целой схемы, как показано в следующем примере:

    EXCLUDE=SCHEMA:”=’HR’”


Параметр INCLUDE является противоположностью параметру EXLCUDE и позволяет принудительно включать в операцию экспорта только определенный набор объектов. Как и в случае параметра EXLCUDE, для указания того, какие точно объекты требуется экспортировать, вместе с INCLUDE тоже можно использовать элемент конструкция_имени.


Ниже приведены три примера, демонстрирующие примеение элемента конструкция_имени для ограничения выбираемых объектов:


    INCLUDE=TABLE:”IN (‘EMPLOYEES’,’DEPARTMENTS’)”;
    INCLUDE=PROCEDURE
    INCLUDE=INDEX:”LIKE ‘EMP%’”



В первом примере параметр INCLUDE указывает, что в процессе экспорта должны приниать участие только две таблицы: ECMPLOYEES и DEPARTMENTS, во втором – только процедуры, а в третьем – только индексы, причем лишь те, имя у которых начинается с EMP.


В следующем примере показано, как использовать символ косой черты для отмены двойных кавычек:


    $ expdp scott/tiger DUMPFIEL=dum.file%U.dmp
    schemas=SCOT EXCLUDE=TABLE:\”=’EMP’\”, EXLUDE=FUNCTION:\”=’MY_FUNCTION’\”


При выполнении фильтрации метаданных за счет применения параметра EXCLUDE и INCLUDE нужно помнить о том, что все объекты, которые зависят от какого-то из фильтуемых объектов, будут обрабатываться тем же образом, что и сам этот фильтруемый объект. Например, в случае использвоания параметра EXCLUDE  для исключения некоторой таблицы также автоматичеки будут исключаться индексы, граничения, триггеры и прочие зависящие от этой тблицы объеекты.


Существует еще множество всевозможных параметров в т.ч. и шиврование, компрессиия и д.р.


<br/>
<h2>Data Pump Import</h2>

    $ nohup impdp scott/tiger dumpfile=datapumps:mydump01.dmp logfile=datapumps:mydump01.log &


Иногда, (в моем случае при неудачном импорте) можно вытащить из файла дампа весь код DDL.

Для этого можно воспользоваться параметром SQLFILE.


    $ nohup impdp scott/tiger dumpfile=datapumps:mydump01.dmp logfile=datapumps:mydump01.log sqlfile=datapumps:scott.sql job_name=scott_import_job_01 &


Создается файл scott.sql с DDL.


<h3>Параметры фильтрации</h3>


Параметр CONTENT применяться в Data Pump Import, как и в Data Pump Export, для указания того, должны ли загружаться только строки (CONTENT=DATA_ONLY), строки и метаданные (CONTENT=ALL), либо только метаданные (CONTENT=METADATA_ONLY).
Параметры EXLCUDE и INCLUDE имеют в Data Pump Import точно такое же предназначение, как и в Data Pump Export, и явялются взаимоисключающими, а в частности:


<ul>
<li>Параметр INCLUDE используется для перечиления объектов, которые необходимо импортировать;</li>
<li>Параметр EXCLUDE применятьтся для перечисления объектов, которые имортировать не требуется.</li>
</ul>


Ниже приведент простой пример использования параметра INCLUDE. В этом примере импорт ограничивается только объектами таблиц. В результате импортирована будет только таблица PERSONS.

    INCLUDE=TABLE:”= ‘persons’ “


Для импорта только тех таблиц, имя у которых начинается с букв PER, можно использоть конструкцию INCLUDE=TABLE:”LIKE ‘PER%’”.  Вдобавок параметр INCLUDE можно применять и отрицательным образом, указывая то, что все объекты  с оперделенным синтаксисом должны игнорироваться:
INCLUDE=TABLE:”NOT LIKE ‘PER%’”


Обратите внимаение на то, что в случае установки для параметра CONTENT занчения DATA_ONLY, использовать во время импорта ни параметр EXCLUDE ни параметр INCLUDE нельзя.


Параметр TABLE_EXISTS_ACTION позволяет указывать Data Pump Import, что следует делать в случае, если таблица уже существует. Для этого параметра можно устанавливать четыре разных значения:


<ul>
<li>SKIP – (значение по умолчанию) – пропукать таблицу, если таковая уже существует;</li>
<li>APPEND – присоединять строки к таблице;</li>
<li>TRUNCATE – усекать таблицу и загружать данные из экспортного файла дампа.</li>
<li>REPLACE – удалять таблицу, если таковая сущствует, создавать ее заново и снова загружать в нее данные.</li>
</ul>


<br/>
<h3>Параметры переопределения</h3>

<br/>
<h3>Параметр REMAP_TABLE</h3>


Параметр REMAP_TABLE  позволяет переименовывать таблицу при выполнении операции импорта с сипользованием метода переноса табличных пространств.


    TABLES=hr. employees REMAP_TABLE=hr. employees:emp

В этом примере параметр REMAP_TABLE указывает, что при выполненении операции импорта имя таблицы hr.employees должно быть изменено на hr.emp


<br/>
<h3>Параметр REMAP_SCHEMA</h3>


Параметр REMAP_SCHEMA позволяет перемещать объекты из одной схемы в другую. Задается этот параметр примерно так:


    REMAP_SCHEMA=hr:oe


В этом примере параметр REMAP_SCHEMA указывает, что при выполнении операции импорта требуется перемесить все объекты из исходной схемы HR в целевую схему OE. Утилита Data Pump Import может даже создать схему OE, если таковой в целевой базе данных не существует.


<br/>
<h3>Параметр REMAP_TABLESPACE</h3>

Иногда бывает нужно, чтобы табличное пространство, в которое выполняется импорт даннных, отличалось от используемого в исходной базе данных. Параметр REMAP_TABLESPACE позволяет осуществлять во время импорта перемещение объектов из одного табличноо пространства в другое.


    REMAP_TABLESPACE=’example_tbs’: ‘new_tbs’



<br/>
<h3>Параметр REMAP_DATAFILE</h3>


При перемещении баз данных между двумя различными платформами, на каждой из которых используетс свое соглашие по именованию фалов,  параметр REMAP_DATAFIE приходится очень кстати, поскольку позволяет изменять формат именования файлов. Ниже приведен пример, показывающий, как с помощью этого параметра указать утилите Data Pump Import, что вместо формата фаловой системы Windows, требуется использовать формат файловой системы UNIX. После этого при обнаружении в экспортном файле дампа людой ссылки на файл с именем в формате файловой истемы Windows, утилита Data Pump Import будет автоматически изменять имя файла в соответствии с форматом файловой системы UNIX.



    REMAP_DATAFIELE=’DB1$:[HRDATA.PAYROLL]tbs6.f’:’/db1/drdata/payroll/tbs6.f’


<h3>Параметры TRANSFORM</h3>


Предположим, что требуется импортировать таблицу из другой схемиы или даже другой азы данных и не импортироват при этом другие атрибуты хранения объектов, т.е. необходимо просто перенести содержациеся в таблице данные. Параметр TRASNSFORM позволяет указать утилите Data Pump Import не импортировать  оперделенные атрибуты хранения и атрибуты других видов. За счет применения параметра TRANSFORM можно исключать из таблицы или индекса конструкции STORAGE и TABLESPACE или только конструкции STORAGE.
При выполнении импорта с помощью Data Pump Oracle создает объекты с использованием DDL-операторов, которые находит в экспортных файлах дампа. Параметр TRANSFORM, по сути, указывает утилите Data Pump Import изменять приводящие к созданию объектов операторы DDL оперделенным образом.


В целом синтаксис параметра TRANSFORM выглядит так:


Ниже приведено краткое описание того, что собой представляет кадый элемент.


<strong>1) Название_трансовармации.</strong> Существуют всего четыре опции, которые могут указываться на месте этого элемента. Эти опции позволяют, соответственно, изменять четыре основных вида характеристик объекта.
<br/><br/>
<ul>
	<li>SEGMENT ATTRIBUTES.  Эта опция позволяет влиять на атриуты сегмента, в число которых вхдят физические атрибуты, атрибуты хранения, табличные пространства и журанлы. Принуждать Data Pump Import  включать все эти атрибтуы можно, указав на месте название_трансформации этой опции со значением Y (SEGMENT_ATTRIBUTES=Y), которое является для этого параметра значением по умолчанию. В таком случае Data Pump Import будет включать все четыре атрибута сегмента вместе с их операторами DDL.</li>
	<li>STORAGE.  За счет указания на месте название_трансформации опции STORAGE со значением Y (STORAGE=Y), представляющее собой значение по умолчанию, можно получать лишь атрибуты хранения тех объектов,  которые являются частью задания Data Pump Import.</li>
	<li>OID.  В случае указания на месте название_трансформации опции OID со значением Y (OID=Y), которое является для нее значением по умолчанию, объектым таблицам во время импорта будет приваиваться новй OID.</li>
	<li>PCTSPACE. За счет указания на месте название_трансформации опции PCTSPACE  с положительным числом в качестве значения можно увеличивать выделяемый  под объекты и файлы данных объем пространства на соответствующее количество процентов.</li>
</ul>


<strong>2) Значение.</strong>  На месте элемента значение в параметре TRANSFORM может указываться либо значение Y (да), либо значение N (нет). Как упоминалось выше, для первых трех опций, которые могут указываться на месте название_трансформации, по умолчанию устанавливается занчение Y.  Это означает, что по умолчанию Data Pump предусмативает выполнение импорта как атрибутов сегмента, так и атрибутов хранения объекта. В качестве альтернативного варианта, для этих опций можно устанавивать значение N и тем самым указывать Data Pump не импортировать исходные атрибуты сегмента и/или  хранения. Что касается опции PCTSPACE, то для нее на месте элемета занчение можнет задваться только какое-то число.


<strong>3) Тип_объекта.</strong> На месте элемета тип_объекта можно указывать  утилите Data Pump Import, объекты какого типа необходимо трансформировать. Это могут быть таблицы, индексы, табличные пространсва, типы, кластеры, граничения и прочие обхекты, в зависимости от опций, указываемых на месте название_транформации. В случае не указания типа подлежащих транформаци обхектов при использовании опции SEGMENT_ATTRIBUTES и STORAGE, эти опции будут применяться ко всем таблицам и индексам, которые являются частью операции импорта.



Ниже приведен пример применения параметра TRANSFORM:



    TRANSFORM=SEGMENT_ATTIBUTES:N:table


В этом примере для SEGMENT_ATTRIBUTES установлено занчение N, а в качестве типа объекта указана таблица. В такой спецификации параметр TRANSFROM указывает утилите Data Pump Import не импортировать существующие атрибуты хранения ни для каких таблиц.



<br/>

## Мониторинг выполнения заданий Data Pump

Наиболее важными для мониторинга за выполнением заданий Data Pump являются
представления DBA_DATAPUMP_JOBS и  DBA_DATAPUMP_SISSIONS.


Представление DBA_DATAPUMP_JOBS позволяет получать сводную информацию обо всех выполняющихся в текущий момент заданиях Data Pump.




    SQL> set pagesize 0;
    SQL> set linesize 220;
    SQL> col owner_name format a20;
    SQL> col job_name format a20;
    SQL> col operation format a20;
    SQL> col state format a20;

    SQL> SELECT owner_name, job_name, operation, state
    FROM dba_datapump_jobs
    WHERE state = 'EXECUTING';

<br/>

    SYS                  IMP_M2M_SVT          IMPORT               EXECUTING




Представление DBA_DATAPUMP_SESSIONS позволяет выяснять, какие пользователькие сеансы в текущий момент подключены к заданию Data Pump Export или Data Pump Import


    SQL> SELECT sid, serial#
    FROM v$session s, dba_datapump_sessions d
    WHERE s.saddr = d.saddr;

<br/>
<h2>Просмотр информации о ходе выполненния заданий Data Pump</h2>


Ниже приведен типичный сценарий, который можнро использовать для получения информаци
о том, сколько времени осталось до завершения выполенения задания Data Pump:

    SQL> SELECT opname, target_desc, sofar, totalwork, start_time, time_remaining
    FROM v$session_longops;

<ul>
	<li>OPNAME - имя задания Data Pump</li>
	<li>TOTALWORK - показывает, сколько всего мегабайт было насчитано для выполненения данного задания;</li>
	<li>SOFA - показывает, сколько пока было передано мегабайт во время выполенения данного задания;</li>
</ul>
